{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76c0001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Reorganized + argparse wrapper for the provided script.\n",
    "\n",
    "Modes:\n",
    "  a) oard_only      : only use OARD (no HPO_db updates; no HPO_db diseases; no HPO_db pair frequencies)\n",
    "  b) oard_first     : prioritize OARD over HPO_db (HPO update + pair freq preference)\n",
    "  c) hpodb_first    : prioritize HPO_db over OARD\n",
    "  d) hpodb_only     : only use HPO_db (no OARD calls)\n",
    "\n",
    "freq_assignment (used when HPO_db is enabled in mode b/c/d):\n",
    "  mean, median, max,\n",
    "  extrinsic_ic, intrinsic_ic, ic (ssmpy.ssm.information_content),\n",
    "  assumption (fallback/else branch: 0.01)\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import ssmpy\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "MVN_CACHE = {}\n",
    "# =========================================================\n",
    "# SSMPY SETUP\n",
    "# =========================================================\n",
    "def init_ssmpy(hp_db_sqlite: str) -> None:\n",
    "    ssmpy.ssm.mica = True\n",
    "    ssmpy.ssm.intrinsic = True\n",
    "    ssmpy.semantic_base(hp_db_sqlite)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# LOAD DATA\n",
    "# =========================================================\n",
    "def load_oard(url: str, dataset_id: str = \"2\"):\n",
    "    # HPO domain\n",
    "    params = {\"dataset_id\": dataset_id, \"domain_id\": \"phenotypes\"}\n",
    "    oard_data = pd.DataFrame(\n",
    "        requests.get(url + \"/frequencies/mostFrequency\", params=params, verify=False)\n",
    "        .json()[\"results\"]\n",
    "    )\n",
    "\n",
    "    hpo_oard = list(set(oard_data[\"concept_code\"]))\n",
    "    oard_hpo_freq_map = oard_data.set_index(\"concept_code\")[\"concept_frequency\"].to_dict()\n",
    "    oard_hpo_code2id = oard_data.set_index(\"concept_code\")[\"concept_id\"].to_dict()\n",
    "\n",
    "    # Disease domain\n",
    "    params = {\"dataset_id\": dataset_id, \"domain_id\": \"diseases\"}\n",
    "    domain_disease_df = pd.DataFrame(\n",
    "        requests.get(url + \"/frequencies/mostFrequency\", params=params, verify=False)\n",
    "        .json()[\"results\"]\n",
    "    )\n",
    "\n",
    "    oard_disease = list(set(domain_disease_df[\"concept_id\"]))\n",
    "\n",
    "    return {\n",
    "        \"oard_data\": oard_data,\n",
    "        \"hpo_oard\": hpo_oard,\n",
    "        \"oard_hpo_freq_map\": oard_hpo_freq_map,\n",
    "        \"oard_hpo_code2id\": oard_hpo_code2id,\n",
    "        \"domain_disease_df\": domain_disease_df,\n",
    "        \"oard_disease\": oard_disease\n",
    "    }\n",
    "\n",
    "\n",
    "def load_hpo_db(hpo_db_path: str):\n",
    "    hpo_db = pd.read_csv(hpo_db_path, sep=\"\\t\")\n",
    "    hpo_db = hpo_db.rename(\n",
    "        columns={\n",
    "            \"hpo_id\": \"concept_code_1\",\n",
    "            \"mondo_id\": \"concept_code_2\",\n",
    "            \"frequency\": \"concept_frequency\",\n",
    "        }\n",
    "    )\n",
    "    hpo_db[\"concept_id_1\"] = hpo_db[\"concept_code_1\"].apply(lambda x: int(x.replace(\"HP:\", \"9\")))\n",
    "    hpo_db[\"concept_id_2\"] = hpo_db[\"concept_code_2\"].apply(lambda x: int(x.replace(\"MONDO:\", \"8\")))\n",
    "\n",
    "    hpo_db_freq_lookup = dict(\n",
    "        zip(\n",
    "            zip(hpo_db[\"concept_code_1\"], hpo_db[\"concept_id_2\"]),\n",
    "            hpo_db[\"concept_frequency\"],\n",
    "        )\n",
    "    )\n",
    "    hpo_db_index = hpo_db.groupby(\"concept_code_1\")[\"concept_id_2\"].apply(list).to_dict()\n",
    "\n",
    "    return {\n",
    "        \"hpo_db\": hpo_db,\n",
    "        \"hpo_db_freq_lookup\": hpo_db_freq_lookup,\n",
    "        \"hpo_db_index\": hpo_db_index,\n",
    "    }\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# MARGINAL FREQ FROM HPO_DB\n",
    "# =========================================================\n",
    "def build_hpo_db_marginal_freq(hpo_db: pd.DataFrame, freq_assignment: str):\n",
    "    \"\"\"\n",
    "    Returns a function: get_freq(hpo_code) -> float\n",
    "    Computes marginal frequency only for requested HPOs (lazy evaluation).\n",
    "    \"\"\"\n",
    "\n",
    "    hpo_db_group = hpo_db.groupby(\"concept_code_1\")[\"concept_frequency\"]\n",
    "    cache = {}\n",
    "\n",
    "    def get_freq(hpo_code: str):\n",
    "\n",
    "        if hpo_code in cache:\n",
    "            return cache[hpo_code]\n",
    "\n",
    "        if freq_assignment == \"mean\":\n",
    "            val = float(hpo_db_group.mean().get(hpo_code, 0.01))\n",
    "\n",
    "        elif freq_assignment == \"median\":\n",
    "            val = float(hpo_db_group.median().get(hpo_code, 0.01))\n",
    "\n",
    "        elif freq_assignment == \"max\":\n",
    "            val = float(hpo_db_group.max().get(hpo_code, 0.01))\n",
    "\n",
    "        elif freq_assignment in {\"extrinsic_ic\", \"intrinsic_ic\", \"ic\"}:\n",
    "            hid = ssmpy.get_id(hpo_code.replace(\":\", \"_\"))\n",
    "            if hid != -1:\n",
    "                if freq_assignment == \"extrinsic_ic\":\n",
    "                    ic = ssmpy.ssm.information_content_extrinsic(hid)\n",
    "                elif freq_assignment == \"intrinsic_ic\":\n",
    "                    ic = ssmpy.ssm.information_content_intrinsic(hid)\n",
    "                else:\n",
    "                    ic = ssmpy.ssm.information_content(hid)\n",
    "                val = float(np.exp(-ic))\n",
    "            else:\n",
    "                val = 0.01\n",
    "\n",
    "        else:  # assumption\n",
    "            val = 0.01\n",
    "\n",
    "        cache[hpo_code] = val\n",
    "        return val\n",
    "\n",
    "    return get_freq\n",
    "def get_hpo_ic_weight(hpo_code, caches, ic_type=\"extrinsic_ic\"):\n",
    "\n",
    "    if not hasattr(caches, \"hpo_ic_cache\"):\n",
    "        caches.hpo_ic_cache = {}\n",
    "\n",
    "    key = (hpo_code, ic_type)\n",
    "    if key in caches.hpo_ic_cache:\n",
    "        return caches.hpo_ic_cache[key]\n",
    "\n",
    "    hid = ssmpy.get_id(hpo_code.replace(\":\", \"_\"))\n",
    "    if hid == -1:\n",
    "        w = 0.0\n",
    "    else:\n",
    "        if ic_type == \"extrinsic_ic\":\n",
    "            w = float(ssmpy.ssm.information_content_extrinsic(hid))\n",
    "        elif ic_type == \"intrinsic_ic\":\n",
    "            w = float(ssmpy.ssm.information_content_intrinsic(hid))\n",
    "        else:\n",
    "            w = float(ssmpy.ssm.information_content(hid))\n",
    "\n",
    "    caches.hpo_ic_cache[key] = w\n",
    "    return w\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# CACHES + SIMILARITY\n",
    "# =========================================================\n",
    "class Caches:\n",
    "    def __init__(self):\n",
    "        self.oard_hpo_api_cache = {}\n",
    "        self.hpo_freq_cache = {}\n",
    "        self.ssmpy_id_cache = {}\n",
    "\n",
    "    def get_ssmpy_id(self, h: str) -> int:\n",
    "        if h not in self.ssmpy_id_cache:\n",
    "            self.ssmpy_id_cache[h] = ssmpy.get_id(h)\n",
    "        return self.ssmpy_id_cache[h]\n",
    "\n",
    "\n",
    "def calc_sim(hpo1: str, hpo2: str, caches: Caches, method: str = \"Resnik\"):\n",
    "    e1 = caches.get_ssmpy_id(hpo1)\n",
    "    e2 = caches.get_ssmpy_id(hpo2)\n",
    "    if e1 == -1 or e2 == -1:\n",
    "        return 0\n",
    "    elif method == \"Resnik\":\n",
    "        return ssmpy.ssm_resnik(e1, e2)\n",
    "    elif method == \"Lin\":\n",
    "        return ssmpy.ssm_lin(e1, e2)\n",
    "    elif method == \"JC\":\n",
    "        return ssmpy.ssm_jiang_conrath(e1, e2)\n",
    "    elif method == \"IC\":\n",
    "        return ssmpy.ssm_lin(e1, e2) * (1 - 1 / (1 + ssmpy.ssm_resnik(e1, e2)))\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# ODDS + UPDATE_HPO (mode-dependent priority)\n",
    "# =========================================================\n",
    "def calc_odd_oard_fast(disease_idx, hpos, hpos_freq, rho, map2freq, x_base, cov_mat, mvn=None):\n",
    "    hpos = [each.replace(\"_\", \":\") for each in hpos]\n",
    "    p = 10 ^ -6\n",
    "    odd_disease = p / (1 - p)\n",
    "\n",
    "    x_disease = x_base.copy()\n",
    "    x_noDisease = x_base.copy()\n",
    "\n",
    "    for i, hpo in enumerate(hpos):\n",
    "        p_yes = map2freq.get((hpo.replace(\":\", \"_\"), disease_idx), -1)\n",
    "        if p_yes != -1:\n",
    "            x_disease[i] = norm.ppf(p_yes)\n",
    "            p_no = (hpos_freq[i] - p_yes * p) / (1 - p)\n",
    "            if p_no < 0:\n",
    "                p_no = 0\n",
    "            x_noDisease[i] = norm.ppf(p_no)\n",
    "\n",
    "    if mvn is None:\n",
    "        joint_prob1 = multivariate_normal.cdf(x_disease, cov=cov_mat)\n",
    "        joint_prob2 = multivariate_normal.cdf(x_noDisease, cov=cov_mat)\n",
    "    else:\n",
    "        joint_prob1 = mvn.cdf(x_disease)\n",
    "        joint_prob2 = mvn.cdf(x_noDisease)\n",
    "\n",
    "\n",
    "    return odd_disease * joint_prob1 / joint_prob2\n",
    "\n",
    "\n",
    "def update_hpo(\n",
    "    hpos,\n",
    "    *,\n",
    "    method: str,\n",
    "    mode: str,\n",
    "    caches: Caches,\n",
    "    # OARD\n",
    "    hpo_oard=None,\n",
    "    oard_hpo_freq_map=None,\n",
    "    # HPO_db marginal\n",
    "    hpo_db_get_marginal_freq=None,\n",
    "    hpo_default_frequency: float = 0.01,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns: (new_hpos, hpo_freq)\n",
    "    Priority is controlled by mode:\n",
    "      - oard_only:     OARD -> map-to-nearest-OARD\n",
    "      - hpodb_only:    HPO_db -> else default\n",
    "      - oard_first:    OARD -> HPO_db -> map-to-nearest-OARD\n",
    "      - hpodb_first:   HPO_db -> OARD -> map-to-nearest-OARD\n",
    "    \"\"\"\n",
    "    new_hpos = []\n",
    "    hpo_freq = []\n",
    "\n",
    "    for hpo in tqdm(hpos, position=1,  dynamic_ncols=True, leave=True):\n",
    "        hpo_code = hpo.replace(\"_\", \":\")\n",
    "\n",
    "        if mode == \"oard_only\":\n",
    "            if hpo_code in (oard_hpo_freq_map or {}):\n",
    "                new_hpos.append(hpo)\n",
    "                hpo_freq.append(float(oard_hpo_freq_map[hpo_code]))\n",
    "                continue\n",
    "            # map to nearest OARD (Resnik)\n",
    "            if hpo not in caches.hpo_freq_cache:\n",
    "                sim_scores = [calc_sim(each.replace(\":\", \"_\"), hpo, caches, method) for each in (hpo_oard or [])]\n",
    "                index_max = int(np.argmax(sim_scores)) if len(sim_scores) else 0\n",
    "                mapped_hpo = hpo_oard[index_max].replace(\":\", \"_\")\n",
    "                caches.hpo_freq_cache[hpo] = mapped_hpo\n",
    "            else:\n",
    "                mapped_hpo = caches.hpo_freq_cache[hpo]\n",
    "\n",
    "            new_hpos.append(mapped_hpo)\n",
    "            mapped_code = mapped_hpo.replace(\"_\", \":\")\n",
    "            hpo_freq.append(float((oard_hpo_freq_map or {}).get(mapped_code, hpo_default_frequency)))\n",
    "            continue\n",
    "\n",
    "        if mode == \"hpodb_only\":\n",
    "            if hpo_db_get_marginal_freq is not None:\n",
    "                val = hpo_db_get_marginal_freq(hpo_code)\n",
    "                if val is not None:\n",
    "                    new_hpos.append(hpo)\n",
    "                    hpo_freq.append(float(val))\n",
    "                    continue\n",
    "            else:\n",
    "                new_hpos.append(hpo)\n",
    "                hpo_freq.append(float(hpo_default_frequency))\n",
    "            continue\n",
    "\n",
    "        if mode == \"oard_first\":\n",
    "            # 1) OARD\n",
    "            if hpo_code in (oard_hpo_freq_map or {}):\n",
    "                new_hpos.append(hpo)\n",
    "                hpo_freq.append(float(oard_hpo_freq_map[hpo_code]))\n",
    "                continue\n",
    "            # 2) HPO_db\n",
    "            if hpo_db_get_marginal_freq is not None:\n",
    "                val = hpo_db_get_marginal_freq(hpo_code)\n",
    "                if val is not None:\n",
    "                    new_hpos.append(hpo)\n",
    "                    hpo_freq.append(float(val))\n",
    "                    continue\n",
    "\n",
    "            # 3) map to nearest OARD\n",
    "            if hpo not in caches.hpo_freq_cache:\n",
    "                sim_scores = [calc_sim(each.replace(\":\", \"_\"), hpo, caches, method) for each in (hpo_oard or [])]\n",
    "                index_max = int(np.argmax(sim_scores)) if len(sim_scores) else 0\n",
    "                mapped_hpo = hpo_oard[index_max].replace(\":\", \"_\")\n",
    "                caches.hpo_freq_cache[hpo] = mapped_hpo\n",
    "            else:\n",
    "                mapped_hpo = caches.hpo_freq_cache[hpo]\n",
    "\n",
    "            new_hpos.append(mapped_hpo)\n",
    "            mapped_code = mapped_hpo.replace(\"_\", \":\")\n",
    "            hpo_freq.append(float((oard_hpo_freq_map or {}).get(mapped_code, hpo_default_frequency)))\n",
    "            continue\n",
    "\n",
    "        if mode == \"hpodb_first\":\n",
    "            # 1) HPO_db\n",
    "            if hpo_db_get_marginal_freq is not None:\n",
    "                val = hpo_db_get_marginal_freq(hpo_code)\n",
    "                if val is not None:\n",
    "                    new_hpos.append(hpo)\n",
    "                    hpo_freq.append(float(val))\n",
    "                    continue\n",
    "            # 2) OARD\n",
    "            if hpo_code in (oard_hpo_freq_map or {}):\n",
    "                new_hpos.append(hpo)\n",
    "                hpo_freq.append(float(oard_hpo_freq_map[hpo_code]))\n",
    "                continue\n",
    "            # 3) map to nearest OARD\n",
    "            if hpo not in caches.hpo_freq_cache:\n",
    "                sim_scores = [calc_sim(each.replace(\":\", \"_\"), hpo, caches, method) for each in (hpo_oard or [])]\n",
    "                index_max = int(np.argmax(sim_scores)) if len(sim_scores) else 0\n",
    "                mapped_hpo = hpo_oard[index_max].replace(\":\", \"_\")\n",
    "                caches.hpo_freq_cache[hpo] = mapped_hpo\n",
    "            else:\n",
    "                mapped_hpo = caches.hpo_freq_cache[hpo]\n",
    "\n",
    "            new_hpos.append(mapped_hpo)\n",
    "            mapped_code = mapped_hpo.replace(\"_\", \":\")\n",
    "            hpo_freq.append(float((oard_hpo_freq_map or {}).get(mapped_code, hpo_default_frequency)))\n",
    "            continue\n",
    "\n",
    "        # Fallback (should not happen)\n",
    "        new_hpos.append(hpo)\n",
    "        hpo_freq.append(float(hpo_default_frequency))\n",
    "\n",
    "    return new_hpos, hpo_freq\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# PATIENT INPUT\n",
    "# =========================================================\n",
    "def load_patients(inputfile: str, *, update_fn):\n",
    "    hpo_patients = {}\n",
    "    freq_patients = {}\n",
    "    with open(inputfile) as infile:\n",
    "        for line in tqdm(infile, position=0, desc = 'Entering patient info'):\n",
    "            parts = line.strip().split()\n",
    "            pid = parts[0]\n",
    "            hpos = parts[1].split(\";\")[:-1]\n",
    "            new_hpos, new_freq = update_fn(hpos)\n",
    "            hpo_patients[pid] = new_hpos\n",
    "            freq_patients[pid] = new_freq\n",
    "    return hpo_patients, freq_patients\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# BUILD disease2freq + hpo2diseases (mode-dependent)\n",
    "# =========================================================\n",
    "def build_disease_maps(\n",
    "    *,\n",
    "    mode: str,\n",
    "    caches: Caches,\n",
    "    url: str,\n",
    "    dataset_id: str,\n",
    "    # patient data\n",
    "    hpo_patients: dict,\n",
    "    # OARD\n",
    "    oard_hpo_code2id=None,\n",
    "    # HPO_db\n",
    "    hpo_db_index=None,\n",
    "    hpo_db_freq_lookup=None,\n",
    "    # preference\n",
    "    prefer: str,  # \"oard\" or \"hpodb\"\n",
    "):\n",
    "    disease2freq = {}\n",
    "    hpo2diseases = defaultdict(set)\n",
    "\n",
    "    final_diseases = set()\n",
    "    all_patient_hpos = set([h for lst in hpo_patients.values() for h in lst])\n",
    "\n",
    "    for each_hpo in tqdm(all_patient_hpos, desc='Retrieving Frequency'):\n",
    "        hpo_key = each_hpo.replace(\":\", \"_\")\n",
    "        each_hpo_code = each_hpo.replace(\"_\", \":\")\n",
    "\n",
    "        # ---- collect candidate diseases ----\n",
    "        if mode in {\"hpodb_only\", \"hpodb_first\", \"oard_first\"}:\n",
    "            final_diseases.update((hpo_db_index or {}).get(each_hpo_code, []))\n",
    "\n",
    "        # ---- OARD pull for this HPO ----\n",
    "        oard_lookup = {}\n",
    "        oard_final_dict = set()\n",
    "        hpo_id = None\n",
    "\n",
    "        if mode in {\"oard_only\", \"oard_first\", \"hpodb_first\"}:\n",
    "            hpo_id = (oard_hpo_code2id or {}).get(each_hpo_code, None)\n",
    "            if hpo_id:\n",
    "                if hpo_id not in caches.oard_hpo_api_cache:\n",
    "                    params = {\"dataset_id\": dataset_id, \"concept_id\": hpo_id}\n",
    "                    result_df = pd.DataFrame(\n",
    "                        requests.get(url + \"/frequencies/mostFrequency\", params=params, verify=False)\n",
    "                        .json()[\"results\"]\n",
    "                    )\n",
    "                    caches.oard_hpo_api_cache[hpo_id] = result_df\n",
    "                else:\n",
    "                    result_df = caches.oard_hpo_api_cache[hpo_id]\n",
    "\n",
    "                if len(result_df) > 0:\n",
    "                    result_df = result_df[result_df[\"concept_id_2\"].astype(str).str.startswith(\"8\")]\n",
    "                    oard_lookup = dict(\n",
    "                        zip(\n",
    "                            zip(result_df[\"concept_id_1\"], result_df[\"concept_id_2\"]),\n",
    "                            result_df[\"concept_frequency\"],\n",
    "                        )\n",
    "                    )\n",
    "                    oard_final_dict = set([d for (_, d) in oard_lookup.keys()])\n",
    "\n",
    "        if mode in {\"oard_only\", \"oard_first\", \"hpodb_first\"}:\n",
    "            final_diseases.update(oard_final_dict)\n",
    "\n",
    "        # ---- fill disease2freq + hpo2diseases ----\n",
    "        for dis in final_diseases:\n",
    "            # preference for pair frequency\n",
    "            if mode == \"oard_only\":\n",
    "                val = oard_lookup.get((hpo_id, dis), -1) if hpo_id else -1\n",
    "\n",
    "            elif mode == \"hpodb_only\":\n",
    "                val = (hpo_db_freq_lookup or {}).get((each_hpo_code, dis), -1)\n",
    "\n",
    "            else:\n",
    "                # mixed\n",
    "                if prefer == \"oard\":\n",
    "                    val = oard_lookup.get((hpo_id, dis), -1) if hpo_id else -1\n",
    "                    if val == -1:\n",
    "                        val = (hpo_db_freq_lookup or {}).get((each_hpo_code, dis), -1)\n",
    "                else:\n",
    "                    val = (hpo_db_freq_lookup or {}).get((each_hpo_code, dis), -1)\n",
    "                    if val == -1:\n",
    "                        val = oard_lookup.get((hpo_id, dis), -1) if hpo_id else -1\n",
    "\n",
    "            disease2freq[(hpo_key, dis)] = val\n",
    "            hpo2diseases[hpo_key].add(dis)\n",
    "\n",
    "    return disease2freq, hpo2diseases\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# RANK PATIENTS\n",
    "# =========================================================\n",
    "def get_mvn_for_dimension(n, cov_mat):\n",
    "    if n not in MVN_CACHE:\n",
    "        MVN_CACHE[n] = multivariate_normal(mean=np.zeros(n), cov=cov_mat)\n",
    "    return MVN_CACHE[n]\n",
    "def computing_phenoss(hpo_patients, freq_patients, disease2freq, hpo2diseases, args, caches):\n",
    "    rank_patients = {}\n",
    "    for pid, patient_hpos in tqdm(hpo_patients.items(), position=0, desc = 'Computing the score'):\n",
    "        patient_freq = freq_patients[pid]\n",
    "\n",
    "        x_base = np.array([norm.ppf(p) for p in patient_freq])\n",
    "        n = len(patient_hpos)\n",
    "\n",
    "        cov_mat = 0.01 * np.ones([n, n])\n",
    "        np.fill_diagonal(cov_mat, 1)\n",
    "\n",
    "        mvn = get_mvn_for_dimension(n, cov_mat)\n",
    "        # ---------- IC-weighted candidate filtering ----------\n",
    "        if args.mode == 'oard_only':\n",
    "            candidate_diseases = set()\n",
    "            for h in patient_hpos:\n",
    "                candidate_diseases.update(hpo2diseases.get(h, []))\n",
    "        else:\n",
    "            if len(patient_hpos) <= 1:\n",
    "                candidate_diseases = set()\n",
    "                for h in patient_hpos:\n",
    "                    candidate_diseases.update(hpo2diseases.get(h, []))\n",
    "            else:\n",
    "\n",
    "                disease_score = defaultdict(float)\n",
    "                disease_count = defaultdict(int)\n",
    "\n",
    "                for h in patient_hpos:\n",
    "                    h_code = h.replace(\"_\", \":\")\n",
    "                    w = get_hpo_ic_weight(h_code, caches)\n",
    "\n",
    "                    for d in hpo2diseases.get(h, []):\n",
    "                        disease_score[d] += w\n",
    "                        disease_count[d] += 1\n",
    "\n",
    "                # sort by IC-weighted score\n",
    "                sorted_items = sorted(\n",
    "                    disease_score.items(),\n",
    "                    key=lambda x: (x[1], disease_count[x[0]]),\n",
    "                    reverse=True\n",
    "                )\n",
    "\n",
    "                TARGET = 500\n",
    "                HARD_CAP = 2000\n",
    "\n",
    "                if len(sorted_items) <= TARGET:\n",
    "                    candidate_diseases = [d for d, _ in sorted_items]\n",
    "                else:\n",
    "                    cutoff_score = sorted_items[TARGET-1][1]\n",
    "\n",
    "                    candidate_diseases = [\n",
    "                        d for d, s in sorted_items\n",
    "                        if s >= cutoff_score\n",
    "                    ]\n",
    "\n",
    "                    if len(candidate_diseases) > HARD_CAP:\n",
    "                        candidate_diseases = [d for d, _ in sorted_items[:HARD_CAP]]\n",
    "        scores = {}\n",
    "        for dis in candidate_diseases:\n",
    "            scores[dis] = calc_odd_oard_fast(\n",
    "                dis,\n",
    "                patient_hpos,\n",
    "                patient_freq,\n",
    "                0.01,\n",
    "                disease2freq,\n",
    "                x_base,\n",
    "                cov_mat,\n",
    "                mvn=mvn\n",
    "            )\n",
    "\n",
    "        rank_patients[pid] = scores\n",
    "        print(\"finished patient:\", pid)\n",
    "\n",
    "    return rank_patients\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# OUTPUT\n",
    "# =========================================================\n",
    "def build_output_df(rank_patients, hpo_db: pd.DataFrame, gene_conversion: bool):\n",
    "    mondo2gene = (\n",
    "        hpo_db.groupby(\"concept_code_2\")[\"gene_symbol\"]\n",
    "        .apply(lambda x: list(set(x.dropna())))\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    records = []\n",
    "    for pid, dis2score in tqdm(rank_patients.items(), desc = 'Finalizing output'):\n",
    "        for dis, score in dis2score.items():\n",
    "            mondo_code = \"MONDO:\" + str(dis)[1:]\n",
    "            records.append(\n",
    "                {\n",
    "                    \"patient_id\": pid,\n",
    "                    \"disease_mondo\": mondo_code,\n",
    "                    \"gene\": mondo2gene.get(mondo_code, np.nan),  # list\n",
    "                    \"disease_id\": dis,\n",
    "                    \"score\": score,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df_out = pd.DataFrame(records)\n",
    "    if gene_conversion:\n",
    "        df_out = df_out.explode(\"gene\", ignore_index=True)\n",
    "\n",
    "        # remove NaN genes\n",
    "        df_out = df_out[df_out[\"gene\"].notna()].copy()\n",
    "\n",
    "    # sort for consistency\n",
    "    df_out.sort_values([\"patient_id\", \"score\"], ascending=[True, True], inplace=True, ignore_index=True)\n",
    "    df_out[\"score\"] = pd.to_numeric(df_out[\"score\"], errors=\"coerce\")\n",
    "\n",
    "    # rerank per patient (same score -> same rank)\n",
    "    df_out[\"rank\"] = (\n",
    "        df_out.groupby(\"patient_id\")[\"score\"].rank(method=\"min\", ascending=True).astype(int)\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    df_out[\"sample_size\"] = len(df_out)\n",
    "    return df_out\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# MAIN\n",
    "# =========================================================\n",
    "def parse_args():\n",
    "    p = argparse.ArgumentParser(description=\"PhenoSS ranking runner (reorganized).\")\n",
    "\n",
    "    p.add_argument(\"--inputfile\", required=True, type=str, help=\"Path to patient input file.\")\n",
    "    p.add_argument(\"--outputfile\", required=True, type=str, help=\"Path to output TSV/CSV.\")\n",
    "\n",
    "    p.add_argument(\n",
    "        \"--mode\",\n",
    "        required=True,\n",
    "        choices=[\"oard_only\", \"oard_first\", \"hpodb_first\", \"hpodb_only\"],\n",
    "        help=(\n",
    "            \"Evaluation mode: \"\n",
    "            \"oard_only (a), oard_first (b), hpodb_first (c), hpodb_only (d).\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    p.add_argument(\n",
    "        \"--freq_assignment\",\n",
    "        default=\"extrinsic_ic\",\n",
    "        choices=[\"mean\", \"median\", \"max\", \"extrinsic_ic\", \"intrinsic_ic\", \"ic\", \"assumption\"],\n",
    "        help=\"How to compute marginal HPO frequencies from HPO_db when HPO_db is enabled.\",\n",
    "    )\n",
    "\n",
    "    p.add_argument(\"--method\", default=\"Resnik\", type=str, help=\"Similarity method for mapping to OARD terms.\")\n",
    "    p.add_argument(\"--hp_db_sqlite\", default=\"hp.db\", type=str, help=\"Path to hp.db for ssmpy.\")\n",
    "    p.add_argument(\"--hpo_db_path\", default=\"hpo_frequency.csv\", type=str, help=\"Path to hpo_frequency.csv (tab-separated).\")\n",
    "    p.add_argument(\"--gene_conversion\", action=\"store_true\", help=\"Convert Mondo IDs to Genes\")\n",
    "\n",
    "    p.add_argument(\"--url\", default=\"https://rare.cohd.io/api\", type=str, help=\"OARD API base url.\")\n",
    "    p.add_argument(\"--dataset_id\", default=\"2\", type=str, help=\"OARD dataset_id (string).\")\n",
    "\n",
    "    # Optional debug extraction like your last lines\n",
    "    p.add_argument(\"--gene_of_interest\", default=None, type=str, help=\"If set, save rows for this gene.\")\n",
    "    p.add_argument(\"--gene_outfile\", default=None, type=str, help=\"If set, write the gene subset to this path.\")\n",
    "\n",
    "    return p.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39df2d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "#/home/nguyenqm/projects/github/LLM-Gene-Prioritization/data/input/PhenoSS_input/all_samples\n",
    "#    inputfile=\"/home/nguyenqm/projects/github/LLM-Gene-Prioritization/data/input/PhenoSS_input/sample2\",\n",
    "\n",
    "args = Namespace(\n",
    "    inputfile=\"/home/nguyenqm/projects/github/LLM-Gene-Prioritization/data/input/PhenoSS_input/sample2\",\n",
    "    outputfile=\"/home/nguyenqm/projects/github/PhenoSS/doc/paper_data/sample2.tsv\",\n",
    "\n",
    "    mode=\"oard_only\",        # \"oard_only\", \"oard_first\", \"hpodb_first\", \"hpodb_only\"\n",
    "    freq_assignment=\"mean\", #\"mean\", \"median\", \"max\", \"extrinsic_ic\", \"intrinsic_ic\", \"ic\", \"assumption\"\n",
    "\n",
    "    method=\"Resnik\", # Lin, JC, IC\n",
    "    hp_db_sqlite=\"hp.db\", # request from https://github.com/lasigeBioTM/DiShIn/tree/master\n",
    "    hpo_db_path=\"./doc/database/hpo_frequency.csv\", ## processed from HPO database\n",
    "    gene_conversion=True,\n",
    "\n",
    "    url=\"https://rare.cohd.io/api\", # OARD\n",
    "    dataset_id=\"2\", # OARD - Columbia\n",
    "\n",
    "    gene_of_interest=\"LMNA\", # optional if having the golden label\n",
    "    gene_outfile=\"/home/nguyenqm/projects/github/PhenoSS/doc/paper_data/lmna.tsv\" # optional if having the golden label\n",
    ")\n",
    "\n",
    "# main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efd7fa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing HPO Database\n",
      "Loading HPO Database\n",
      "Loading OARD Database\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing HPO Database\")\n",
    "init_ssmpy(args.hp_db_sqlite)\n",
    "\n",
    "caches = Caches()\n",
    "\n",
    "# Load HPO_db (always loaded because output step needs mondo2gene from it in your code)\n",
    "print(\"Loading HPO Database\")\n",
    "hpo_db_pack = load_hpo_db(args.hpo_db_path)\n",
    "hpo_db = hpo_db_pack[\"hpo_db\"]\n",
    "hpo_db_freq_lookup = hpo_db_pack[\"hpo_db_freq_lookup\"]\n",
    "hpo_db_index = hpo_db_pack[\"hpo_db_index\"]\n",
    "\n",
    "# Load OARD only if mode needs it\n",
    "print(\"Loading OARD Database\")\n",
    "if args.mode in {\"oard_only\", \"oard_first\", \"hpodb_first\"}:\n",
    "    oard_pack = load_oard(args.url, dataset_id=args.dataset_id)\n",
    "    hpo_oard = oard_pack[\"hpo_oard\"]\n",
    "    oard_hpo_freq_map = oard_pack[\"oard_hpo_freq_map\"]\n",
    "    oard_hpo_code2id = oard_pack[\"oard_hpo_code2id\"]\n",
    "else:\n",
    "    hpo_oard = []\n",
    "    oard_hpo_freq_map = {}\n",
    "    oard_hpo_code2id = {}\n",
    "\n",
    "# Build HPO_db marginal freq only if mode uses HPO_db during update_hpo\n",
    "if args.mode in {\"hpodb_only\", \"hpodb_first\", \"oard_first\"}:\n",
    "    hpo_db_get_marginal_freq = build_hpo_db_marginal_freq(hpo_db, args.freq_assignment)\n",
    "else:\n",
    "    hpo_db_get_marginal_freq = {}\n",
    "\n",
    "hpo_default_frequency = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f17be569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Patient Information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entering patient info: 0it [00:00, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [09:01<00:00, 180.46s/it]\u001b[A\n",
      "Entering patient info: 1it [09:01, 541.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# update_hpo wrapper with mode + resources\n",
    "def _update_fn(hpos):\n",
    "    return update_hpo(\n",
    "        hpos,\n",
    "        method=args.method,\n",
    "        mode=args.mode,\n",
    "        caches=caches,\n",
    "        hpo_oard=hpo_oard,\n",
    "        oard_hpo_freq_map=oard_hpo_freq_map,\n",
    "        hpo_db_get_marginal_freq=hpo_db_get_marginal_freq,\n",
    "        hpo_default_frequency=hpo_default_frequency,\n",
    "    )\n",
    "\n",
    "# Load patients\n",
    "print(\"Loading Patient Information\")\n",
    "hpo_patients, freq_patients = load_patients(args.inputfile, update_fn=_update_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8b49e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building HPO-Disease Mapping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving Frequency: 100%|██████████| 3/3 [00:01<00:00,  2.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# disease2freq / hpo2diseases\n",
    "if args.mode == \"oard_first\":\n",
    "    prefer = \"oard\"\n",
    "elif args.mode == \"hpodb_first\" or args.mode == \"hpodb_only\":\n",
    "    prefer = \"hpodb\"\n",
    "else:\n",
    "    prefer = \"oard\"\n",
    "\n",
    "print(\"Building HPO-Disease Mapping\")\n",
    "disease2freq, hpo2diseases = build_disease_maps(\n",
    "    mode=args.mode,\n",
    "    caches=caches,\n",
    "    url=args.url,\n",
    "    dataset_id=args.dataset_id,\n",
    "    hpo_patients=hpo_patients,\n",
    "    oard_hpo_code2id=oard_hpo_code2id,\n",
    "    hpo_db_index=hpo_db_index,\n",
    "    hpo_db_freq_lookup=hpo_db_freq_lookup,\n",
    "    prefer=prefer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8c3014f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PhenoSS scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing the score: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished patient: sample1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute PhenoSS scores\n",
    "print(\"Computing PhenoSS scores\")\n",
    "phenoss_computation = computing_phenoss(hpo_patients, freq_patients, disease2freq, hpo2diseases, args, caches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83e198ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finalizing output: 100%|██████████| 1/1 [00:00<00:00, 3672.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>disease_mondo</th>\n",
       "      <th>gene</th>\n",
       "      <th>disease_id</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "      <th>sample_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample1</td>\n",
       "      <td>MONDO:0007330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80007330</td>\n",
       "      <td>-0.931332</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample1</td>\n",
       "      <td>MONDO:0007452</td>\n",
       "      <td>[HNF4A]</td>\n",
       "      <td>80007452</td>\n",
       "      <td>-0.410588</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample1</td>\n",
       "      <td>MONDO:0023646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80023646</td>\n",
       "      <td>-0.343263</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample1</td>\n",
       "      <td>MONDO:0015074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80015074</td>\n",
       "      <td>-0.297980</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample1</td>\n",
       "      <td>MONDO:0016410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80016410</td>\n",
       "      <td>-0.285374</td>\n",
       "      <td>5</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>sample1</td>\n",
       "      <td>MONDO:0016367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80016367</td>\n",
       "      <td>-0.011221</td>\n",
       "      <td>170</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>sample1</td>\n",
       "      <td>MONDO:0008433</td>\n",
       "      <td>[RB1]</td>\n",
       "      <td>80008433</td>\n",
       "      <td>-0.011011</td>\n",
       "      <td>171</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>sample1</td>\n",
       "      <td>MONDO:0017853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80017853</td>\n",
       "      <td>-0.010604</td>\n",
       "      <td>172</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>sample1</td>\n",
       "      <td>MONDO:0016370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80016370</td>\n",
       "      <td>-0.010178</td>\n",
       "      <td>173</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>sample1</td>\n",
       "      <td>MONDO:0019121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80019121</td>\n",
       "      <td>-0.010178</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    patient_id  disease_mondo     gene  disease_id     score  rank  \\\n",
       "0      sample1  MONDO:0007330      NaN    80007330 -0.931332     1   \n",
       "1      sample1  MONDO:0007452  [HNF4A]    80007452 -0.410588     2   \n",
       "2      sample1  MONDO:0023646      NaN    80023646 -0.343263     3   \n",
       "3      sample1  MONDO:0015074      NaN    80015074 -0.297980     4   \n",
       "4      sample1  MONDO:0016410      NaN    80016410 -0.285374     5   \n",
       "..         ...            ...      ...         ...       ...   ...   \n",
       "169    sample1  MONDO:0016367      NaN    80016367 -0.011221   170   \n",
       "170    sample1  MONDO:0008433    [RB1]    80008433 -0.011011   171   \n",
       "171    sample1  MONDO:0017853      NaN    80017853 -0.010604   172   \n",
       "172    sample1  MONDO:0016370      NaN    80016370 -0.010178   173   \n",
       "173    sample1  MONDO:0019121      NaN    80019121 -0.010178   174   \n",
       "\n",
       "     sample_size  \n",
       "0            174  \n",
       "1            174  \n",
       "2            174  \n",
       "3            174  \n",
       "4            174  \n",
       "..           ...  \n",
       "169          174  \n",
       "170          174  \n",
       "171          174  \n",
       "172          174  \n",
       "173          174  \n",
       "\n",
       "[174 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output dataframe\n",
    "print(\"Building output\")\n",
    "df_out = build_output_df(phenoss_computation, hpo_db, False)\n",
    "df_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phenogpt2",
   "language": "python",
   "name": "phenogpt2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
